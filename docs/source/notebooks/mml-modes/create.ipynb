{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create mode\n",
    "\n",
    "This notebook depicts the `create` mode. It is used to generate the underlying data for a task. Task creation is the very first step that needs to be taken\n",
    "in order to use it for processing. The `mml-tasks` plugin provides the creators to generate a variety of tasks. But we stick to the `mml_fake_task` implemented in\n",
    "`mml-core` for simplicity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:37:27.007079Z",
     "start_time": "2024-01-17T13:37:15.577387Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2025-05-02 22:13:11,242\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - Started MML 1.0.4 on Python 3.10.17 with mode CREATE.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,242\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - Plugins loaded: ['mml-tasks']\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,599\u001b[0m][\u001b[34mmml.core.scripts.schedulers.create_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Skipping creation of task mml_fake_task because there already seems to be a RAW version of that.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,600\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - MML init time was 0.0h 0.0m  0.36s.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,602\u001b[0m][\u001b[34mmml.core.scripts.schedulers.create_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting task creation!\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,602\u001b[0m][\u001b[34mmml.core.data_loading.file_manager\u001b[0m][\u001b[32mINFO\u001b[0m] - A total of 0 paths have been created during this run.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,603\u001b[0m][\u001b[34mmml.core.scripts.schedulers.base_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Successfully finished all experiments!\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:11,603\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - MML run time was 0.0h 0.0m  0.00s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mml create task_list=[mml_fake_task]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "After creation we can see some information on the task with `info` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:37:49.923265Z",
     "start_time": "2024-01-17T13:37:45.355221Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2025-05-02 22:13:21,893\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - Started MML 1.0.4 on Python 3.10.17 with mode INFO.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:21,893\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - Plugins loaded: ['mml-tasks']\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,231\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Was given no study name to search for, so showing all studies with project prefix.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,234\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - MML init time was 0.0h 0.0m  0.34s.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,236\u001b[0m][\u001b[34mmml.core.scripts.schedulers.base_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Preparing experiment ...\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,237\u001b[0m][\u001b[34mmml.core.scripts.schedulers.base_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting experiment!\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,238\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting info on task \u001b[33m\u001b[46m\u001b[1mmml_fake_task\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,238\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Task name: mml_fake_task\n",
      "Task type: classification\n",
      "Num classes: 10\n",
      "Means: RGBInfo(r=0.49829596281051636, g=0.49836331605911255, b=0.498288631439209)\n",
      "Stds: RGBInfo(r=0.1517328917980194, g=0.15169444680213928, b=0.1517714262008667)\n",
      "Sizes: Sizes(min_height=256, max_height=256, min_width=256, max_width=256)\n",
      "Class occ: {'H': 89, 'E': 93, 'A': 93, 'J': 96, 'C': 103, 'F': 93, 'I': 127, 'G': 90, 'D': 121, 'B': 95}\n",
      "Preprocessed: default\n",
      "Task keywords: ['artificial']\n",
      "paths: {}\n",
      "models: []\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,250\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Num samples (full train set): 1000\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,250\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Default validation class occurrences are: {2: 21, 7: 18, 9: 19, 0: 19, 3: 24, 8: 25, 4: 19, 1: 19, 5: 19, 6: 18}\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,251\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Finished info on task \u001b[33m\u001b[46m\u001b[1mmml_fake_task\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,252\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting plotting sample grid of all tasks.\u001b[0m\n",
      "Loading samples:   0%|                                    | 0/1 [00:00<?, ?it/s][\u001b[36m2025-05-02 22:13:22,254\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /home/scholzpa/Documents/development/github/mml/src/mml/core/data_loading/lightning_datamodule.py:319: Deactivated normalization for task mml_fake_task.\n",
      "\u001b[0m\n",
      "Loading samples: 100%|████████████████████████████| 1/1 [00:00<00:00, 35.90it/s]\n",
      "[\u001b[36m2025-05-02 22:13:22,294\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Finished plotting sample grid. Can be found at /home/scholzpa/Documents/exp/mml_results/default/PLOTS/sample_grid/grid_0112.png.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,305\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Finished plotting individual samples for each task.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,307\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Model info shows only loaded models (not all existing!). Use reuse.models=... to select a project to load models from.\u001b[0m\n",
      "\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\n",
      "\u001b[34m|\u001b[0m\u001b[96m task \u001b[34m|\u001b[0m\u001b[96m created \u001b[34m|\u001b[0m\u001b[96m fold \u001b[34m|\u001b[0m\u001b[96m performance \u001b[34m|\u001b[0m\u001b[96m training (secs) \u001b[34m|\u001b[0m\u001b[96m params? \u001b[34m|\u001b[0m\u001b[96m preds? \u001b[34m|\u001b[0m\u001b[96m\n",
      "\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\n",
      "\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[34m-\u001b[0m\u001b[96m\u001b[36m+\u001b[0m\u001b[96m\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,308\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - No models found for 1 tasks (['mml_fake_task']).\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,309\u001b[0m][\u001b[34mmml.core.scripts.schedulers.info_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Total number of all samples: 1000.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,309\u001b[0m][\u001b[34mmml.core.data_loading.file_manager\u001b[0m][\u001b[32mINFO\u001b[0m] - A total of 2 paths have been created during this run.\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,309\u001b[0m][\u001b[34mmml.core.scripts.schedulers.base_scheduler\u001b[0m][\u001b[32mINFO\u001b[0m] - Successfully finished all experiments!\u001b[0m\n",
      "[\u001b[36m2025-05-02 22:13:22,309\u001b[0m][\u001b[34mmml\u001b[0m][\u001b[32mINFO\u001b[0m] - MML run time was 0.0h 0.0m  0.08s.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mml info task_list=[mml_fake_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
